import xml.etree.ElementTree as ET
import json
from lxml import etree
import os

class TableAnalyzer:
    def __init__(self, xml_file):
        self.xml_file = xml_file
        self.ns = {
            'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
            'w14': 'http://schemas.microsoft.com/office/word/2010/wordml'
        }
        self.tree = etree.parse(xml_file)
        self.root = self.tree.getroot()
        
    def get_cell_text(self, cell):
        """è·å–å•å…ƒæ ¼ä¸­çš„æ‰€æœ‰æ–‡æœ¬"""
        texts = []
        for t in cell.findall('.//w:t', self.ns):
            if t.text:
                texts.append(t.text)
        return ''.join(texts).strip()
    
    def analyze_table(self, table_index=0):
        """åˆ†æè¡¨æ ¼å¹¶è¿”å›æ‰€æœ‰å•å…ƒæ ¼çš„åæ ‡ä¿¡æ¯"""
        tables = self.root.findall('.//w:tbl', self.ns)
        
        if not tables or table_index >= len(tables):
            return None
            
        table = tables[table_index]
        table_xpath = f"/w:document/w:body/w:tbl[{table_index + 1}]"
        
        cells_data = []
        rows = table.findall('w:tr', self.ns)
        
        for row_idx, row in enumerate(rows):
            cells = row.findall('w:tc', self.ns)
            
            for col_idx, cell in enumerate(cells):
                cell_text = self.get_cell_text(cell)
                
                # æ„å»ºXPath - ä¸åŒæ–¹å¼è·å–
                cell_xpath = f"{table_xpath}/w:tr[{row_idx + 1}]/w:tc[{col_idx + 1}]"
                
                # è·å–gridSpanå’ŒvMergeä¿¡æ¯
                tc_pr = cell.find('w:tcPr', self.ns)
                grid_span = 1
                v_merge = None
                
                if tc_pr is not None:
                    gs = tc_pr.find('w:gridSpan', self.ns)
                    if gs is not None:
                        grid_span = int(gs.get('{%s}val' % self.ns['w'], '1'))
                    
                    vm = tc_pr.find('w:vMerge', self.ns)
                    if vm is not None:
                        v_merge = vm.get('{%s}val' % self.ns['w'], 'continue')
                
                cell_info = {
                    "cell_id": f"cell_{row_idx}_{col_idx}",
                    "row": row_idx,
                    "col": col_idx,
                    "grid_span": grid_span,
                    "v_merge": v_merge,
                    "xpath": cell_xpath,
                    "label": cell_text,
                    "is_empty": len(cell_text) == 0,
                    "row_display": f"ç¬¬{row_idx + 1}è¡Œ",
                    "col_display": f"ç¬¬{col_idx + 1}åˆ—",
                    "position": f"({row_idx}, {col_idx})"
                }
                
                cells_data.append(cell_info)
        
        return {
            "table_index": table_index,
            "table_name": "(ä¸€)åŸºæœ¬æƒ…å†µè¡¨",
            "total_rows": len(rows),
            "total_cols": len(rows[0].findall('w:tc', self.ns)) if rows else 0,
            "cells": cells_data
        }
    
    def save_to_json(self, output_file, table_data):
        """ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(table_data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ è¡¨æ ¼åæ ‡æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")


def main():
    xml_file = 'split_pages/page_8.xml'
    output_file = 'table_coordinates.json'
    
    if not os.path.exists(xml_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {xml_file}")
        return
    
    analyzer = TableAnalyzer(xml_file)
    table_data = analyzer.analyze_table(table_index=0)
    
    if table_data:
        print(f"\nğŸ“Š è¡¨æ ¼åˆ†æç»“æœ:")
        print(f"  è¡¨åç§°: {table_data['table_name']}")
        print(f"  è¡Œæ•°: {table_data['total_rows']}")
        print(f"  åˆ—æ•°: {table_data['total_cols']}")
        print(f"  æ€»å•å…ƒæ ¼æ•°: {len(table_data['cells'])}")
        print(f"  ç©ºç™½å•å…ƒæ ¼æ•°: {sum(1 for c in table_data['cells'] if c['is_empty'])}")
        
        print(f"\nğŸ“ å•å…ƒæ ¼åæ ‡ä¿¡æ¯ç¤ºä¾‹:")
        for i, cell in enumerate(table_data['cells'][:5]):
            print(f"\n  {i+1}. {cell['cell_id']}")
            print(f"     ä½ç½®: {cell['position']}")
            print(f"     XPath: {cell['xpath']}")
            print(f"     æ ‡ç­¾/å†…å®¹: {cell['label']}")
            print(f"     æ˜¯å¦ç©ºç™½: {cell['is_empty']}")
        
        print(f"\n  ... (å…± {len(table_data['cells'])} ä¸ªå•å…ƒæ ¼)\n")
        
        analyzer.save_to_json(output_file, table_data)
        
        # è¾“å‡ºå…³é”®å•å…ƒæ ¼çš„è¯¦ç»†åæ ‡
        print(f"ğŸ“‹ å…³é”®å­—æ®µçš„åæ ‡:")
        for cell in table_data['cells']:
            if cell['label'] and not cell['is_empty']:
                print(f"  {cell['label']:15} -> {cell['position']:12} -> {cell['xpath']}")
    else:
        print("âŒ æœªæ‰¾åˆ°è¡¨æ ¼")


if __name__ == '__main__':
    main()
